{
  "run": {
    "run_id": "enterprise-2025-09-03T05-19-41Z",
    "waves": [
      [
        "compute_ai_penetration",
        "compute_api_reliability",
        "compute_backlog_aging",
        "compute_case_resolution_time",
        "compute_change_failure_rate",
        "compute_data_sync_latency",
        "compute_dq_exceptions_rate",
        "compute_duplicate_record_rate",
        "compute_hr_onboarding_cycle_time",
        "compute_incident_reopen_rate",
        "compute_lead_to_oppty_cycle_time",
        "compute_platform_customization_debt",
        "compute_process_automation_coverage",
        "compute_procure_to_pay_cycle",
        "compute_q2c_throughput",
        "compute_rpa_success_rate",
        "compute_workflow_sla_adherence"
      ],
      [
        "compute_integration_topology_health"
      ],
      [
        "compute_ai_governance_coverage"
      ],
      [
        "compute_ai_outcome_uplift"
      ]
    ]
  },
  "scores": {
    "categories": {
      "data_management": 78.57,
      "analytics_readiness": 73.46
    },
    "overall": 76.53
  },
  "metrics": {
    "compute_ai_penetration": {
      "metric_id": "ai.penetration",
      "band": "C",
      "rationale": "AI is included in 45% of workflows, but only 42% of executions utilize AI features; the execution share is below the threshold for a higher band. The strongest positive is the inclusion of AI in nearly half of the workflows, while the limiting factor is the execution share being below 50%.",
      "flags": [],
      "gaps": [
        "Execution share low → increase AI execution share → target ≥50% (unlocks band 4)."
      ],
      "MetricID": "ai.penetration",
      "Score": 3,
      "score_0to100": 70
    },
    "compute_api_reliability": {
      "metric_id": "api.reliability",
      "band": "B",
      "rationale": "The p95 latency is within the SLO, but the error rate slightly exceeds the acceptable threshold; this indicates good reliability with room for improvement. The strongest positive is the latency performance, while the limiting factor is the error rate just above 0.5%.",
      "flags": [],
      "gaps": [
        "Error rate exceeds SLO → reduce error rate to ≤0.5% → solidifies band 5."
      ],
      "MetricID": "api.reliability",
      "Score": 4,
      "score_0to100": 85
    },
    "compute_backlog_aging": {
      "metric_id": "backlog.aging",
      "band": "C",
      "rationale": "The median age of open items is 2.2 days, which is within the acceptable range for band 4, but the 90th percentile age of 5.5 days limits the overall score. The strong point is the relatively low median age, while the higher 90th percentile indicates some items are aging more than desired.",
      "flags": [],
      "gaps": [
        "High p90 age → reduce aging of older items → achieve p90 ≤5d (unlocks band 4)."
      ],
      "MetricID": "backlog.aging",
      "Score": 3,
      "score_0to100": 70
    },
    "compute_case_resolution_time": {
      "metric_id": "itsm.case_resolution_time",
      "band": "C",
      "rationale": "The median resolution time of 95 minutes is within the fair range, but the p90 of 180 minutes indicates significant delays for some cases. The strong volume of resolved tickets (700) is a positive aspect, but the high p90 limits the overall performance assessment.",
      "flags": [],
      "gaps": [
        "High p90 indicates delays → analyze resolution times by priority level → target p90 ≤ 90m (unlocks band 4)."
      ],
      "MetricID": "itsm.case_resolution_time",
      "Score": 3,
      "score_0to100": 70
    },
    "compute_change_failure_rate": {
      "metric_id": "change.failure_rate",
      "band": "C",
      "rationale": "A 9% change failure rate indicates some reliability issues; while the total deploys are substantial, the failure count is significant enough to limit confidence. The strong positive is the total number of deploys, but the failure rate is above the threshold for a higher band.",
      "flags": [
        "moderate_cfr"
      ],
      "gaps": [
        "Failure causes unclear → implement detailed tracking of failure reasons for each deploy → achieve ≤5% failure rate (unlocks band 4)."
      ],
      "MetricID": "change.failure_rate",
      "Score": 3,
      "score_0to100": 70
    },
    "compute_data_sync_latency": {
      "metric_id": "integration.data_sync_latency",
      "band": "B",
      "rationale": "The median of 75s and p95 of 160s indicate good performance, but they are on the edge of the next band. The failure rate is low at 0.2%, which is a strong positive aspect.",
      "flags": [
        "good_performance"
      ],
      "gaps": [
        "Latency nearing upper limits → optimize delivery processes → target median ≤60s and p95 ≤120s (unlocks band 5)."
      ],
      "MetricID": "integration.data_sync_latency",
      "Score": 4,
      "score_0to100": 85
    },
    "compute_dq_exceptions_rate": {
      "metric_id": "dq.exceptions_rate",
      "band": "C",
      "rationale": "The exception rate of 3.2% indicates a fair level of data quality, but the presence of 90 failed checks suggests significant issues that need addressing. The weighted severity of 1.2 is relatively low, which is a positive aspect.",
      "flags": [],
      "gaps": [
        "High exception rate → analyze failed checks for root causes → reduce rate to ≤3% (unlocks band 4)."
      ],
      "MetricID": "dq.exceptions_rate",
      "Score": 3,
      "score_0to100": 70
    },
    "compute_duplicate_record_rate": {
      "metric_id": "mdm.duplicate_rate",
      "band": "B",
      "rationale": "A 5.5% duplicate rate indicates a good level of matching, but the presence of 44 duplicate groups suggests room for improvement in standardization. The strongest positive is the relatively low duplicate rate, while the limiting factor is the number of duplicate groups detected.",
      "flags": [
        "moderate_dupes"
      ],
      "gaps": [
        "High number of duplicate groups → implement stricter matching criteria and data cleansing processes → achieve ≤3% duplicate rate (unlocks band 5)."
      ],
      "MetricID": "mdm.duplicate_rate",
      "Score": 4,
      "score_0to100": 85
    },
    "compute_hr_onboarding_cycle_time": {
      "metric_id": "hr.onboarding_cycle_time",
      "band": "C",
      "rationale": "Median 50h indicates a fair onboarding process, but the p90 of 72h suggests that some hires experience significant delays; the approval process may be a limiting factor.",
      "flags": [],
      "gaps": [
        "Approval delays evident → analyze approval step durations and identify top bottlenecks → reduce p90 to ≤48h (unlocks band 4)."
      ],
      "MetricID": "hr.onboarding_cycle_time",
      "Score": 3,
      "score_0to100": 70
    },
    "compute_incident_reopen_rate": {
      "metric_id": "itsm.incident_reopen_rate",
      "band": "C",
      "rationale": "Reopen rate of 8.5% indicates a fair level of first-time resolution, but it is above the threshold for a higher band. The number of reopened incidents suggests there may be underlying issues affecting resolution quality.",
      "flags": [],
      "gaps": [
        "Root causes unclear → analyze top reasons for reopenings and implement corrective actions → reduce reopen rate to ≤7% (unlocks band 4)."
      ],
      "MetricID": "itsm.incident_reopen_rate",
      "Score": 3,
      "score_0to100": 70
    },
    "compute_lead_to_oppty_cycle_time": {
      "metric_id": "sales.lead_to_oppty_cycle_time",
      "band": "C",
      "rationale": "Median hours of 26 is fair, but the p90 at 48 indicates a significant tail risk. The strong sample size of 400 provides some reliability, but the higher p90 limits the overall assessment.",
      "flags": [],
      "gaps": [
        "Tail risk unknown → add p95/p99 latency and failure % for the conversion path → keep p90 within 24h (unlocks band 4)."
      ],
      "MetricID": "sales.lead_to_oppty_cycle_time",
      "Score": 3,
      "score_0to100": 70
    },
    "compute_platform_customization_debt": {
      "metric_id": "platform.customization_debt",
      "band": "C",
      "rationale": "Moderate customization footprint with a significant number of Apex classes and a reasonable count of custom records; however, the index indicates a higher risk level due to the number of transports and custom steps. The strong point is the relatively low number of custom records, but the high count of Apex classes limits the overall stability.",
      "flags": [],
      "gaps": [
        "High customization risk → reduce Apex classes and transports → achieve ≤80 Apex classes and ≤5 transports (unlocks band 4)."
      ],
      "MetricID": "platform.customization_debt",
      "Score": 3,
      "score_0to100": 70
    },
    "compute_process_automation_coverage": {
      "metric_id": "process.automation.coverage",
      "band": "B",
      "rationale": "The coverage ratio of 0.72 indicates good automation across multiple platforms, with active flows in Salesforce, ServiceNow, and Workday. However, the coverage is not sufficient to reach the highest band due to the need for more consistent execution across these platforms.",
      "flags": [
        "multi_platform_coverage"
      ],
      "gaps": [
        "Execution regularity not verified → publish runs/week per platform for last 4 weeks → confirm consistent cadence (unlocks band 5)."
      ],
      "MetricID": "process.automation.coverage",
      "Score": 4,
      "score_0to100": 85
    },
    "compute_procure_to_pay_cycle": {
      "metric_id": "sap.procure_to_pay_cycle",
      "band": "C",
      "rationale": "Total days of 10.5 indicates a fair performance; while approval days are strong at 1.2, the total duration exceeds the 9-12 day range. The limiting factor is the total days from PO creation to invoice posting.",
      "flags": [],
      "gaps": [
        "Total days excessive → reduce GR and invoice days → target ≤8d (unlocks band 4)."
      ],
      "MetricID": "sap.procure_to_pay_cycle",
      "Score": 3,
      "score_0to100": 70
    },
    "compute_q2c_throughput": {
      "metric_id": "q2c.throughput",
      "band": "C",
      "rationale": "The total of 30 hours indicates a fair performance; however, the time from sales order to billing at 20 hours is a significant delay that limits overall efficiency. The strong point is the quick transition from quote approval to sales order at 10 hours.",
      "flags": [],
      "gaps": [
        "SO to billing delay → streamline billing process → reduce to ≤24h (unlocks band 4)."
      ],
      "MetricID": "q2c.throughput",
      "Score": 3,
      "score_0to100": 70
    },
    "compute_rpa_success_rate": {
      "metric_id": "rpa.success_rate",
      "band": "B",
      "rationale": "Overall success rate is 94%, which is strong, but the SAP system is slightly below the threshold at 93%. This limits the overall band despite good performance from the SF system.",
      "flags": [
        "high_reliability"
      ],
      "gaps": [
        "SAP system underperformance → analyze failure causes and implement improvements → achieve ≥95% success rate on SAP (unlocks band 5)."
      ],
      "MetricID": "rpa.success_rate",
      "Score": 4,
      "score_0to100": 85
    },
    "compute_workflow_sla_adherence": {
      "metric_id": "workflow.sla_adherence",
      "band": "B",
      "rationale": "The overall on-time rate is 0.91, which is good, but the performance of individual systems shows that both SF and SN are below the 0.95 threshold. Improving the lower-performing system will help achieve a higher band.",
      "flags": [
        "sf_trailing",
        "sn_trailing"
      ],
      "gaps": [
        "Coverage uneven by platform → report on-time rates per system weekly → achieve ≥0.95 on both SF and SN (unlocks band 5)."
      ],
      "MetricID": "workflow.sla_adherence",
      "Score": 4,
      "score_0to100": 85
    },
    "compute_integration_topology_health": {
      "metric_id": "integration.topology_health",
      "band": "B",
      "rationale": "All nodes are healthy with an average uptime of 99.7% and no critical errors; however, the presence of only 3 nodes limits the robustness of the assessment. The strong positive is the absence of critical errors, while the limiting factor is the small number of nodes monitored.",
      "flags": [
        "nodes_green"
      ],
      "gaps": [
        "limited node count → expand monitoring to additional nodes → achieve ≥5 nodes healthy (unlocks band 5)."
      ],
      "MetricID": "integration.topology_health",
      "Score": 4,
      "score_0to100": 85
    },
    "compute_ai_governance_coverage": {
      "metric_id": "ai.governance_coverage",
      "band": "B",
      "rationale": "Coverage is at 78%, which is good, but it falls short of the excellent threshold. The presence of only 2 alerts in the last 30 days indicates effective monitoring, but the overall coverage is the limiting factor.",
      "flags": [
        "policies_covered"
      ],
      "gaps": [
        "Coverage below 90% → increase models with all controls to ≥45 → achieve ≥90% coverage (unlocks band 5)."
      ],
      "MetricID": "ai.governance_coverage",
      "Score": 4,
      "score_0to100": 85
    },
    "compute_ai_outcome_uplift": {
      "metric_id": "ai.outcome_uplift",
      "band": "D",
      "rationale": "The estimated uplift of 11% indicates a positive change, but the post-AI KPI value has decreased from the baseline, which is a significant limiting factor. This contradiction suggests instability in the improvement.",
      "flags": [],
      "gaps": [
        "Post-AI KPI decline → investigate root causes and implement corrective actions → achieve ≥10% uplift consistently (unlocks band 4)."
      ],
      "MetricID": "ai.outcome_uplift",
      "Score": 2,
      "score_0to100": 55
    }
  },
  "snapshot_meta": {
    "collected_at": "2025-09-03T05:19:41.822921+00:00"
  }
}
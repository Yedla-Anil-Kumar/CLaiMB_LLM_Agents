[
  {
    "agent": "enterprise_systems",
    "scores": {
      "process_maturity": 3.64,
      "integration_health": 3.61,
      "ai_outcomes": 3.62,
      "platform_risk": 3.0
    },
    "metric_breakdown": {
      "process.automation.coverage": {
        "metric_id": "process.automation.coverage",
        "band": 4,
        "rationale": "The coverage ratio of 0.72 indicates good automation across multiple platforms, but it falls short of the excellent threshold. The limiting factor is the need for broader coverage across more platforms to reach the highest band.",
        "flags": [],
        "gaps": [
          "Coverage uneven by platform → report coverage per platform and runs/week → achieve ≥0.85 coverage on ≥3 platforms (unlocks band 5)."
        ],
        "MetricID": "process.automation.coverage",
        "Score": 4
      },
      "workflow.sla_adherence": {
        "metric_id": "workflow.sla_adherence",
        "band": 4,
        "rationale": "On-time rate of 0.91 indicates good adherence to SLAs, with a strong performance overall; however, it is just below the threshold for an excellent rating.",
        "flags": [],
        "gaps": [
          "On-time rate near threshold → improve processes to increase on_time rate to ≥0.95 → achieve consistent excellent performance (unlocks band 5)."
        ],
        "MetricID": "workflow.sla_adherence",
        "Score": 4
      },
      "sales.lead_to_oppty_cycle_time": {
        "metric_id": "sales.lead_to_oppty_cycle_time",
        "band": 3,
        "rationale": "The median of 28 hours is fair, but it exceeds the upper limit for band 3; the p90 is not provided, which limits understanding of tail risk. Strongest positive is the sample size, which suggests a reasonable data set for analysis.",
        "flags": [],
        "gaps": [
          "Tail risk unknown → add p90 hours for lead to opportunity conversion → keep p90 ≤48h (unlocks band 4)."
        ],
        "MetricID": "sales.lead_to_oppty_cycle_time",
        "Score": 3
      },
      "itsm.case_resolution_time": {
        "metric_id": "itsm.case_resolution_time",
        "band": 5,
        "rationale": "The median resolution time of 15 minutes indicates excellent performance, and the absence of limiting factors supports this high rating.",
        "flags": [],
        "gaps": [],
        "MetricID": "itsm.case_resolution_time",
        "Score": 5
      },
      "itsm.incident_reopen_rate": {
        "metric_id": "itsm.incident_reopen_rate",
        "band": 5,
        "rationale": "The reopen rate of 5% indicates a strong performance in resolving incidents on the first attempt. However, the overall percentage is approaching the upper limit of the band, which suggests a need for ongoing monitoring.",
        "flags": [],
        "gaps": [
          "Reopen rate nearing upper limit → analyze trends in reopen rates over time → maintain rate ≤2% (unlocks band 5)."
        ],
        "MetricID": "itsm.incident_reopen_rate",
        "Score": 5
      },
      "hr.onboarding_cycle_time": {
        "metric_id": "hr.onboarding_cycle_time",
        "band": 1,
        "rationale": "The median hours of 7 indicates a critical delay in the onboarding process; however, the lack of additional context on approval steps limits the assessment. The strong positive is the low median hours, but the critical band is due to the absence of data on approval tail risks.",
        "flags": [],
        "gaps": [
          "Approval process unclear → analyze approval step durations and identify bottlenecks → reduce median approval time to ≤24h (unlocks band 5)."
        ],
        "MetricID": "hr.onboarding_cycle_time",
        "Score": 1
      },
      "sap.procure_to_pay_cycle": {
        "metric_id": "sap.procure_to_pay_cycle",
        "band": 1,
        "rationale": "The total days of 18 exceeds the critical threshold of 20 days, indicating significant delays in the process; the lack of sub-stage timing details limits understanding of specific bottlenecks.",
        "flags": [],
        "gaps": [
          "High total days → analyze each stage for delays → reduce total days to ≤20 (unlocks band 2)."
        ],
        "MetricID": "sap.procure_to_pay_cycle",
        "Score": 1
      },
      "q2c.throughput": {
        "metric_id": "q2c.throughput",
        "band": 5,
        "rationale": "The total of 10 hours from quote approval to billing is excellent; however, reliance on specific approver windows may affect consistency in the future.",
        "flags": [
          "fast_time_to_cash"
        ],
        "gaps": [
          "Variability unknown → analyze approval times by team → ensure ≤12h for all teams (solidifies band 5)."
        ],
        "MetricID": "q2c.throughput",
        "Score": 5
      },
      "backlog.aging": {
        "metric_id": "backlog.aging",
        "band": 5,
        "rationale": "The median age of open items is excellent at 0.8 days and the 90th percentile is also within the optimal range at 2.5 days; however, there may be hidden hotspots in specific queues that need monitoring.",
        "flags": [
          "low_queue_age"
        ],
        "gaps": [
          "Hidden pockets possible → publish per-queue age p95 and oldest 10 items → keep all queues p90 ≤3d (maintains band 5)."
        ],
        "MetricID": "backlog.aging",
        "Score": 5
      },
      "rpa.success_rate": {
        "metric_id": "rpa.success_rate",
        "band": 4,
        "rationale": "The overall success rate is 93%, which is good, but it is on the lower end of the band. There is no information on retries or failures by system, which limits the assessment of reliability.",
        "flags": [],
        "gaps": [
          "Lack of per-system data → report success rates and failure reasons by system → achieve ≥95% success on all systems (unlocks band 5)."
        ],
        "MetricID": "rpa.success_rate",
        "Score": 4
      },
      "integration.data_sync_latency": {
        "metric_id": "integration.data_sync_latency",
        "band": 5,
        "rationale": "The median of 12 seconds and p95 of 12 seconds indicate excellent performance with no failures reported.",
        "flags": [
          "excellent_performance"
        ],
        "gaps": [],
        "MetricID": "integration.data_sync_latency",
        "Score": 5
      },
      "api.reliability": {
        "metric_id": "api.reliability",
        "band": 5,
        "rationale": "The error rate of 0.1% is well below the SLO threshold, indicating excellent reliability; however, the p95 latency is not provided, which limits the assessment of latency performance. ",
        "flags": [],
        "gaps": [
          "p95 latency unknown → provide p95 latency data for all endpoints → ensure p95 meets SLO (solidifies band 5)."
        ],
        "MetricID": "api.reliability",
        "Score": 5
      },
      "integration.topology_health": {
        "metric_id": "integration.topology_health",
        "band": 1,
        "rationale": "The average uptime is significantly low at 0.7%, indicating systemic failures across the integration nodes. The absence of healthy nodes and the presence of critical errors further exacerbate the situation.",
        "flags": [],
        "gaps": [
          "systemic failures → implement monitoring and remediation strategies → achieve ≥99.5% uptime across all nodes (unlocks band 3)."
        ],
        "MetricID": "integration.topology_health",
        "Score": 1
      },
      "mdm.duplicate_rate": {
        "metric_id": "mdm.duplicate_rate",
        "band": 4,
        "rationale": "A 3% duplicate rate indicates good matching and standardization; however, the absence of detailed trends or breakdowns limits confidence in consistency.",
        "flags": [
          "low_dupes"
        ],
        "gaps": [
          "Trend and source mix unknown → provide monthly duplicate trend and breakdown by source system → maintain ≤2% across sources (unlocks band 5)."
        ],
        "MetricID": "mdm.duplicate_rate",
        "Score": 4
      },
      "dq.exceptions_rate": {
        "metric_id": "dq.exceptions_rate",
        "band": 3,
        "rationale": "The exception rate of 6% indicates a fair level of data quality, but the higher rate suggests significant issues. The lack of detail on severity and specific failed checks limits the assessment.",
        "flags": [],
        "gaps": [
          "High exception rate → analyze failed checks by severity → reduce rate to ≤3% (unlocks band 4)."
        ],
        "MetricID": "dq.exceptions_rate",
        "Score": 3
      },
      "ai.penetration": {
        "metric_id": "ai.penetration",
        "band": 3,
        "rationale": "AI features are included in 55% of workflows, but the execution share is not provided, limiting the overall assessment. The positive aspect is the decent coverage of workflows, while the lack of execution data prevents a higher band rating.",
        "flags": [],
        "gaps": [
          "Execution share unknown → measure execution share of AI features → achieve ≥50% execution share (unlocks band 4)."
        ],
        "MetricID": "ai.penetration",
        "Score": 3
      },
      "ai.outcome_uplift": {
        "metric_id": "ai.outcome_uplift",
        "band": 4,
        "rationale": "An estimated uplift of 11% indicates a good improvement; however, the stability of this uplift over time is not confirmed.",
        "flags": [
          "strong_uplift"
        ],
        "gaps": [
          "Stability unproven → include last 8–12 weeks trend for median and p90 → demonstrate non-declining trend (solidifies band 5)."
        ],
        "MetricID": "ai.outcome_uplift",
        "Score": 4
      },
      "ai.governance_coverage": {
        "metric_id": "ai.governance_coverage",
        "band": 4,
        "rationale": "Governance coverage is at 82%, which is strong, but there is no information on alerts or potential issues that could affect compliance. The absence of alerts suggests stability, but the lack of detailed monitoring could be a limiting factor.",
        "flags": [],
        "gaps": [
          "Lack of alert context → implement a monitoring system for governance alerts → achieve ≤5 alerts/month (unlocks band 5)."
        ],
        "MetricID": "ai.governance_coverage",
        "Score": 4
      },
      "platform.customization_debt": {
        "metric_id": "platform.customization_debt",
        "band": 4,
        "rationale": "The customization index indicates a moderate-low footprint, suggesting a well-managed environment; however, the lack of detailed risk assessment limits confidence in stability.",
        "flags": [
          "moderate_low_footprint"
        ],
        "gaps": [
          "Risk assessment lacking → implement detailed tracking of unmanaged customizations and deprecated API usage → maintain unmanaged/deprecated at 0 (unlocks band 5)."
        ],
        "MetricID": "platform.customization_debt",
        "Score": 4
      },
      "change.failure_rate": {
        "metric_id": "change.failure_rate",
        "band": 2,
        "rationale": "A 14% change failure rate indicates significant reliability issues; while the deployment count is not provided, the high failure rate is concerning. The lack of detailed deployment data limits the ability to assess the overall impact and trends.",
        "flags": [],
        "gaps": [
          "High failure rate → implement a robust pre-deployment testing strategy → reduce failure rate to ≤12% (unlocks band 3)."
        ],
        "MetricID": "change.failure_rate",
        "Score": 2
      }
    },
    "mode": "single_inputs_json"
  },
  {
    "agent": "enterprise_systems",
    "scores": {
      "process_maturity": 3.06,
      "integration_health": 2.88,
      "ai_outcomes": 3.0,
      "platform_risk": 2.0
    },
    "metric_breakdown": {
      "process.automation.coverage": {
        "metric_id": "process.automation.coverage",
        "band": 3,
        "rationale": "The coverage ratio of 0.61 indicates a fair level of automation, but it suggests that the automation is siloed or patchy across the platforms. The strongest positive is the presence of some automated objects, while the limiting factor is the uneven distribution of automation across platforms.",
        "flags": [],
        "gaps": [
          "Coverage uneven by platform → report coverage per platform and runs/week → achieve ≥0.70 coverage on ≥2 platforms (unlocks band 4)."
        ],
        "MetricID": "process.automation.coverage",
        "Score": 3
      },
      "workflow.sla_adherence": {
        "metric_id": "workflow.sla_adherence",
        "band": 2,
        "rationale": "The on-time rate of 0.77 indicates a significant gap in meeting SLAs, with the performance falling into the poor category. This low adherence suggests systemic issues that need addressing.",
        "flags": [],
        "gaps": [
          "On-time rate low → implement process improvements and monitoring → achieve on-time rate ≥0.80 (unlocks band 3)."
        ],
        "MetricID": "workflow.sla_adherence",
        "Score": 2
      },
      "sales.lead_to_oppty_cycle_time": {
        "metric_id": "sales.lead_to_oppty_cycle_time",
        "band": 4,
        "rationale": "Median of 19h is good, and while it falls within the acceptable range, the p90 tail is not provided, which limits the assessment of potential outliers. The strong point is the median being below 24h, but the lack of p90 data raises concerns about tail risk.",
        "flags": [],
        "gaps": [
          "Tail risk unknown → add p90 latency for lead to opportunity conversion → keep p90 within 24h (unlocks band 5)."
        ],
        "MetricID": "sales.lead_to_oppty_cycle_time",
        "Score": 4
      },
      "itsm.case_resolution_time": {
        "metric_id": "itsm.case_resolution_time",
        "band": 5,
        "rationale": "The median resolution time of 25 minutes indicates excellent performance, and the absence of limiting factors supports this high rating.",
        "flags": [],
        "gaps": [],
        "MetricID": "itsm.case_resolution_time",
        "Score": 5
      },
      "itsm.incident_reopen_rate": {
        "metric_id": "itsm.incident_reopen_rate",
        "band": 3,
        "rationale": "Reopen rate of 12% indicates a fair level of first-time resolution, but it is above the acceptable threshold for a higher band. The strongest positive is that the rate is not excessively high, but the limiting factor is that it exceeds the 8-12% range for band 3.",
        "flags": [],
        "gaps": [
          "Reopen causes unclear → analyze top reasons for reopens and implement corrective actions → achieve ≤8% reopen rate (unlocks band 4)."
        ],
        "MetricID": "itsm.incident_reopen_rate",
        "Score": 3
      },
      "hr.onboarding_cycle_time": {
        "metric_id": "hr.onboarding_cycle_time",
        "band": 5,
        "rationale": "The median onboarding time of 12 hours is excellent, indicating a highly efficient process; however, the approval tail has not been evaluated for potential delays.",
        "flags": [
          "fast_bp"
        ],
        "gaps": [
          "Approval delays unmeasured → analyze approval step durations → ensure all steps are ≤24h (solidifies band 5)."
        ],
        "MetricID": "hr.onboarding_cycle_time",
        "Score": 5
      },
      "sap.procure_to_pay_cycle": {
        "metric_id": "sap.procure_to_pay_cycle",
        "band": 1,
        "rationale": "The total days of 21 exceeds the critical threshold; while there may be some efficiency in sub-stages, the overall process is severely delayed.",
        "flags": [],
        "gaps": [
          "Excessive total days → analyze each stage for delays → reduce total days to ≤20 (unlocks band 2)."
        ],
        "MetricID": "sap.procure_to_pay_cycle",
        "Score": 1
      },
      "q2c.throughput": {
        "metric_id": "q2c.throughput",
        "band": 1,
        "rationale": "The total hours exceed 96h, indicating a critical delay in the time-to-cash process; the strong positive is the initial quote approval, but the overall duration is severely limiting.",
        "flags": [],
        "gaps": [
          "Process inefficiencies → analyze bottlenecks in quote approval and billing → reduce total hours to ≤96h (unlocks band 2)."
        ],
        "MetricID": "q2c.throughput",
        "Score": 1
      },
      "backlog.aging": {
        "metric_id": "backlog.aging",
        "band": 5,
        "rationale": "The median age of open items is very low (p50 0.8d, p90 2.5d), indicating efficient processing; however, potential hotspots in specific queues are not identified.",
        "flags": [
          "low_queue_age"
        ],
        "gaps": [
          "Hidden pockets possible → publish per-queue age p95 and oldest 10 items → keep all queues p90 ≤3d (maintains band 5)."
        ],
        "MetricID": "backlog.aging",
        "Score": 5
      },
      "rpa.success_rate": {
        "metric_id": "rpa.success_rate",
        "band": 3,
        "rationale": "The overall success rate is 81%, which is within the fair range, but does not meet the threshold for a higher band. The strongest positive is that the rate is above 70%, indicating some reliability, while the limiting factor is the failure rate that keeps it from achieving a better score.",
        "flags": [],
        "gaps": [
          "Failure rate high → analyze failure causes and implement fixes → achieve ≥85% success rate (unlocks band 4)."
        ],
        "MetricID": "rpa.success_rate",
        "Score": 3
      },
      "integration.data_sync_latency": {
        "metric_id": "integration.data_sync_latency",
        "band": 4,
        "rationale": "The median of 35s and p95 of 35s indicate good performance, but the lack of failure percentage data limits the assessment.",
        "flags": [
          "good_performance"
        ],
        "gaps": [
          "Failure context missing → provide failure % and retry metrics → keep failures <0.5% (unlocks band 5)."
        ],
        "MetricID": "integration.data_sync_latency",
        "Score": 4
      },
      "api.reliability": {
        "metric_id": "api.reliability",
        "band": 5,
        "rationale": "The error rate is significantly below the threshold, indicating excellent reliability; however, the p95 latency is not provided, which limits the assessment of latency performance. ",
        "flags": [],
        "gaps": [
          "p95 latency unknown → provide p95 latency metrics for all endpoints → ensure p95 latency meets SLO (unlocks band 5)."
        ],
        "MetricID": "api.reliability",
        "Score": 5
      },
      "integration.topology_health": {
        "metric_id": "integration.topology_health",
        "band": 1,
        "rationale": "The average uptime is significantly low at 0.58%, indicating systemic failures across the integration nodes. This critical issue overshadows any potential positives, leading to a severe rating.",
        "flags": [],
        "gaps": [
          "systemic failures → implement monitoring and remediation for uptime → achieve ≥99.5% uptime across all nodes (unlocks band 3)."
        ],
        "MetricID": "integration.topology_health",
        "Score": 1
      },
      "mdm.duplicate_rate": {
        "metric_id": "mdm.duplicate_rate",
        "band": 3,
        "rationale": "A 9% duplicate rate indicates a fair level of matching but suggests room for improvement; the strongest positive is the detection of duplicates, while the limiting factor is the higher-than-ideal duplicate rate.",
        "flags": [],
        "gaps": [
          "High duplicate rate → implement stricter matching criteria and data cleansing processes → achieve ≤5% duplicates (unlocks band 4)."
        ],
        "MetricID": "mdm.duplicate_rate",
        "Score": 3
      },
      "dq.exceptions_rate": {
        "metric_id": "dq.exceptions_rate",
        "band": 1,
        "rationale": ">10% exception rate indicates critical data quality issues; the high rate is the strongest limiting factor.",
        "flags": [],
        "gaps": [
          "High exception rate → implement targeted data quality checks and remediation processes → reduce rate to ≤1% (unlocks band 5)."
        ],
        "MetricID": "dq.exceptions_rate",
        "Score": 1
      },
      "ai.penetration": {
        "metric_id": "ai.penetration",
        "band": 3,
        "rationale": "AI is present in 33% of workflows, but the execution share is not provided, limiting the overall assessment. The positive aspect is that a third of workflows utilize AI features, indicating some level of adoption.",
        "flags": [],
        "gaps": [
          "Execution share unknown → measure execution share of AI workflows → achieve ≥50% execution share (unlocks band 4)."
        ],
        "MetricID": "ai.penetration",
        "Score": 3
      },
      "ai.outcome_uplift": {
        "metric_id": "ai.outcome_uplift",
        "band": 3,
        "rationale": "The estimated uplift of 5% indicates a modest improvement; however, it does not meet the threshold for a higher band. The strongest positive is the uplift itself, while the limiting factor is the insufficient percentage to reach a higher band.",
        "flags": [],
        "gaps": [
          "Uplift insufficient → increase improvement strategies and measure impact → achieve ≥10% uplift (unlocks band 4)."
        ],
        "MetricID": "ai.outcome_uplift",
        "Score": 3
      },
      "ai.governance_coverage": {
        "metric_id": "ai.governance_coverage",
        "band": 3,
        "rationale": "Coverage is at 65%, which is fair, but does not meet the threshold for a higher band; the lack of alerts suggests some stability in governance. However, the coverage is below the 75% mark, limiting the overall assessment.",
        "flags": [],
        "gaps": [
          "Coverage below target → increase models with required controls → achieve ≥75% coverage (unlocks band 4)."
        ],
        "MetricID": "ai.governance_coverage",
        "Score": 3
      },
      "platform.customization_debt": {
        "metric_id": "platform.customization_debt",
        "band": 3,
        "rationale": "The customization risk index indicates a moderate level of customization, suggesting some stability; however, the lack of detailed metrics on specific customizations limits the assessment of risk. The strongest positive is the moderate index value, while the absence of comprehensive risk details is a limiting factor.",
        "flags": [],
        "gaps": [
          "Lack of detailed risk metrics → implement tracking for unmanaged customizations and deprecated API usage → maintain unmanaged/deprecated at 0 (unlocks band 4)."
        ],
        "MetricID": "platform.customization_debt",
        "Score": 3
      },
      "change.failure_rate": {
        "metric_id": "change.failure_rate",
        "band": 1,
        "rationale": "A change failure rate of 25% indicates a critical reliability issue; while the high number of deploys suggests activity, the failure rate is significantly above acceptable thresholds. This high failure rate severely limits the overall effectiveness of the deployment process.",
        "flags": [
          "high_cfr"
        ],
        "gaps": [
          "High failure rate → implement rigorous pre-deployment testing and validation processes → reduce failure rate to ≤3% (unlocks band 5)."
        ],
        "MetricID": "change.failure_rate",
        "Score": 1
      }
    },
    "mode": "single_inputs_json"
  },
  {
    "agent": "enterprise_systems",
    "scores": {
      "process_maturity": 3.06,
      "integration_health": 2.88,
      "ai_outcomes": 1.62,
      "platform_risk": 2.5
    },
    "metric_breakdown": {
      "process.automation.coverage": {
        "metric_id": "process.automation.coverage",
        "band": 2,
        "rationale": "The coverage ratio of 0.44 indicates sporadic automation across the platforms, with significant gaps in coverage. While there is some automation present, it is not sufficient to ensure reliable performance across the systems.",
        "flags": [],
        "gaps": [
          "Low coverage ratio → increase automated objects and workflows across platforms → achieve ≥0.70 coverage (unlocks band 4)."
        ],
        "MetricID": "process.automation.coverage",
        "Score": 2
      },
      "workflow.sla_adherence": {
        "metric_id": "workflow.sla_adherence",
        "band": 2,
        "rationale": "The on-time rate is below 0.70, indicating significant issues with meeting SLAs; while there is a measurable completion rate, it is insufficient to meet expectations.",
        "flags": [],
        "gaps": [
          "On-time rate low → implement process improvements and training → achieve on-time rate ≥0.80 (unlocks band 3)."
        ],
        "MetricID": "workflow.sla_adherence",
        "Score": 2
      },
      "sales.lead_to_oppty_cycle_time": {
        "metric_id": "sales.lead_to_oppty_cycle_time",
        "band": 3,
        "rationale": "The median of 35 hours indicates a fair performance, but the lack of p90 data limits understanding of tail risk. The strongest positive is that the median is below the 48-hour threshold, but the absence of p90 information raises concerns about potential delays.",
        "flags": [],
        "gaps": [
          "Tail risk unknown → add p90 latency for lead to opportunity conversion → keep p90 ≤48h (unlocks band 4)."
        ],
        "MetricID": "sales.lead_to_oppty_cycle_time",
        "Score": 3
      },
      "itsm.case_resolution_time": {
        "metric_id": "itsm.case_resolution_time",
        "band": 5,
        "rationale": "Median 40m with p90 70m indicates efficient resolution times; however, the impact of different priority incidents is not detailed.",
        "flags": [
          "low_tail_risk"
        ],
        "gaps": [
          "Priority mix unclear → break out p50/p90 by P1/P2/P3 → ensure P1 p90 ≤90m (solidifies band 5)."
        ],
        "MetricID": "itsm.case_resolution_time",
        "Score": 5
      },
      "itsm.incident_reopen_rate": {
        "metric_id": "itsm.incident_reopen_rate",
        "band": 2,
        "rationale": "The reopen rate of 15% indicates a significant issue with first-time resolution, which is a critical limiting factor. While the reopen rate is lower than 20%, it still falls within the poor performance range.",
        "flags": [],
        "gaps": [
          "Root causes unclear → analyze reasons for reopenings and implement targeted training → achieve ≤10% reopen rate (unlocks band 3)."
        ],
        "MetricID": "itsm.incident_reopen_rate",
        "Score": 2
      },
      "hr.onboarding_cycle_time": {
        "metric_id": "hr.onboarding_cycle_time",
        "band": 5,
        "rationale": "Median 20h with p90 36h is fast; dependency on specific approver chains not assessed.",
        "flags": [
          "fast_bp"
        ],
        "gaps": [
          "Bottlenecks hidden → list top 3 longest approval steps with median/p90 → keep worst-step p90 ≤48h (solidifies band 5)."
        ],
        "MetricID": "hr.onboarding_cycle_time",
        "Score": 5
      },
      "sap.procure_to_pay_cycle": {
        "metric_id": "sap.procure_to_pay_cycle",
        "band": 1,
        "rationale": "The total days of 29 is critical; the process is significantly delayed. The strongest positive is the identification of the issue, but the overall timing is far beyond acceptable limits.",
        "flags": [],
        "gaps": [
          "Excessive total days → analyze each stage for bottlenecks → reduce total days to ≤20d (unlocks band 2)."
        ],
        "MetricID": "sap.procure_to_pay_cycle",
        "Score": 1
      },
      "q2c.throughput": {
        "metric_id": "q2c.throughput",
        "band": 5,
        "rationale": "10 hours total is elite; dependence on specific approver windows could limit resilience.",
        "flags": [
          "fast_time_to_cash"
        ],
        "gaps": [
          "Variability unknown → slice throughput by product family/region → keep p90 ≤18h across segments (solidifies band 5)."
        ],
        "MetricID": "q2c.throughput",
        "Score": 5
      },
      "backlog.aging": {
        "metric_id": "backlog.aging",
        "band": 5,
        "rationale": "The median age of open items is excellent at 0.8 days and the 90th percentile is also within the optimal range at 2.5 days; however, there may be hidden hotspots in specific queues that need monitoring.",
        "flags": [
          "low_queue_age"
        ],
        "gaps": [
          "Hidden pockets possible → publish per-queue age p95 and oldest 10 items → keep all queues p90 ≤3d (maintains band 5)."
        ],
        "MetricID": "backlog.aging",
        "Score": 5
      },
      "rpa.success_rate": {
        "metric_id": "rpa.success_rate",
        "band": 1,
        "rationale": "The overall success ratio is 63%, which is below the critical threshold of 70%. This indicates significant reliability issues in RPA runs. The strong positive is that there is a measurable success rate, but the high failure rate is a major limiting factor.",
        "flags": [],
        "gaps": [
          "High failure rate → implement root cause analysis and improve error handling → achieve ≥70% success rate (unlocks band 2)."
        ],
        "MetricID": "rpa.success_rate",
        "Score": 1
      },
      "integration.data_sync_latency": {
        "metric_id": "integration.data_sync_latency",
        "band": 4,
        "rationale": "The median of 55s is within the acceptable range for band 4, and the p95 of 55s is also strong. However, without failure percentage data, we cannot confirm the reliability of the delivery.",
        "flags": [],
        "gaps": [
          "Failure context missing → provide failure % and retry metrics → keep failures <0.5% (unlocks band 5)."
        ],
        "MetricID": "integration.data_sync_latency",
        "Score": 4
      },
      "api.reliability": {
        "metric_id": "api.reliability",
        "band": 5,
        "rationale": "The error rate is significantly below the threshold at 0.1%, indicating excellent reliability; however, the p95 latency is not provided, which limits the assessment of latency performance. ",
        "flags": [],
        "gaps": [
          "p95 latency unknown → provide p95 latency metrics for all endpoints → ensure p95 latency meets SLO (unlocks band 5)."
        ],
        "MetricID": "api.reliability",
        "Score": 5
      },
      "integration.topology_health": {
        "metric_id": "integration.topology_health",
        "band": 1,
        "rationale": "The average uptime is significantly low at 0.41%, indicating systemic failures across the integration nodes. This critical issue overshadows any potential positives, leading to a severe rating.",
        "flags": [],
        "gaps": [
          "systemic failures → implement monitoring and remediation for uptime → achieve ≥99.9% uptime (unlocks band 5)."
        ],
        "MetricID": "integration.topology_health",
        "Score": 1
      },
      "mdm.duplicate_rate": {
        "metric_id": "mdm.duplicate_rate",
        "band": 2,
        "rationale": "A 16% duplicate rate indicates significant issues with entity matching and standardization; while the detection is in place, the high rate is concerning.",
        "flags": [
          "high_dupes"
        ],
        "gaps": [
          "High duplicate rate → improve matching algorithms and data quality processes → target ≤10% duplicates (unlocks band 3)."
        ],
        "MetricID": "mdm.duplicate_rate",
        "Score": 2
      },
      "dq.exceptions_rate": {
        "metric_id": "dq.exceptions_rate",
        "band": 2,
        "rationale": "The exception rate of 19% indicates a critical level of issues, despite the absence of detailed severity data. The high failure rate is the primary limiting factor, overshadowing any potential positives.",
        "flags": [],
        "gaps": [
          "High exception rate → implement targeted rule reviews and fixes → reduce rate to ≤10% (unlocks band 3)."
        ],
        "MetricID": "dq.exceptions_rate",
        "Score": 2
      },
      "ai.penetration": {
        "metric_id": "ai.penetration",
        "band": 1,
        "rationale": "Only 18% of executions utilize AI features, indicating minimal adoption; the lack of workflows with AI features further limits effectiveness.",
        "flags": [],
        "gaps": [
          "Low execution share → increase AI feature integration in workflows → achieve ≥30% executions with AI (unlocks band 3)."
        ],
        "MetricID": "ai.penetration",
        "Score": 1
      },
      "ai.outcome_uplift": {
        "metric_id": "ai.outcome_uplift",
        "band": 2,
        "rationale": "The estimated uplift of 2% indicates minimal improvement; the lack of significant change limits the overall effectiveness of the AI rollout.",
        "flags": [],
        "gaps": [
          "Minimal uplift → identify specific areas of inefficiency and implement targeted AI solutions → achieve ≥10% uplift (unlocks band 4)."
        ],
        "MetricID": "ai.outcome_uplift",
        "Score": 2
      },
      "ai.governance_coverage": {
        "metric_id": "ai.governance_coverage",
        "band": 2,
        "rationale": "Only 39% of models have the required governance controls, indicating significant gaps in compliance; the lack of sufficient coverage is the primary limiting factor.",
        "flags": [],
        "gaps": [
          "Coverage low → increase share of models with required controls → achieve ≥75% coverage (unlocks band 4)."
        ],
        "MetricID": "ai.governance_coverage",
        "Score": 2
      },
      "platform.customization_debt": {
        "metric_id": "platform.customization_debt",
        "band": 3,
        "rationale": "The customization risk index indicates a moderate level of customization, which is a concern; however, the low count of custom records and transports suggests some stability. The limiting factor is the overall index value, which reflects a need for better management of customizations.",
        "flags": [],
        "gaps": [
          "Moderate customization risk → implement a review process for customizations and their impacts → achieve a lower index value (unlocks band 4)."
        ],
        "MetricID": "platform.customization_debt",
        "Score": 3
      },
      "change.failure_rate": {
        "metric_id": "change.failure_rate",
        "band": 2,
        "rationale": "A change failure rate of 33% indicates significant reliability issues; while the high failure rate is a strong negative, there is no evidence of improvement or stability trends provided.",
        "flags": [],
        "gaps": [
          "High failure rate → implement stricter pre-deployment testing and validation processes → reduce failure rate to ≤20% (unlocks band 3)."
        ],
        "MetricID": "change.failure_rate",
        "Score": 2
      }
    },
    "mode": "single_inputs_json"
  },
  {
    "agent": "enterprise_systems",
    "scores": {
      "process_maturity": 3.86,
      "integration_health": 3.66,
      "ai_outcomes": 3.62,
      "platform_risk": 2.5
    },
    "metric_breakdown": {
      "process.automation.coverage": {
        "metric_id": "process.automation.coverage",
        "band": 4,
        "rationale": "The coverage ratio of 0.72 indicates good automation across multiple platforms, with ServiceNow slightly outperforming others. However, the coverage is not consistent across all platforms, limiting the overall score.",
        "flags": [
          "multi_platform_coverage"
        ],
        "gaps": [
          "Coverage uneven by platform → report coverage per platform and runs/week → achieve ≥0.85 coverage on ≥3 platforms (unlocks band 5)."
        ],
        "MetricID": "process.automation.coverage",
        "Score": 4
      },
      "workflow.sla_adherence": {
        "metric_id": "workflow.sla_adherence",
        "band": 4,
        "rationale": "The overall on-time rate of 0.91 is strong, with high priority cases performing even better at 0.94; however, normal priority cases at 0.89 slightly limit the overall performance.",
        "flags": [],
        "gaps": [
          "Normal priority cases lagging → improve normal priority case handling → achieve ≥0.90 on-time rate for normal cases (unlocks band 5)."
        ],
        "MetricID": "workflow.sla_adherence",
        "Score": 4
      },
      "sales.lead_to_oppty_cycle_time": {
        "metric_id": "sales.lead_to_oppty_cycle_time",
        "band": 3,
        "rationale": "The median of 28 hours is fair, but the p90 at 52 hours indicates a significant tail risk. This discrepancy suggests that while some leads convert reasonably quickly, others take much longer, limiting overall performance.",
        "flags": [],
        "gaps": [
          "Tail risk unknown → add p95/p99 latency and failure % for lead conversion → keep p90 within 48h (unlocks band 4)."
        ],
        "MetricID": "sales.lead_to_oppty_cycle_time",
        "Score": 3
      },
      "itsm.case_resolution_time": {
        "metric_id": "itsm.case_resolution_time",
        "band": 5,
        "rationale": "The median resolution time of 15 minutes and a p90 of 35 minutes indicate excellent performance in resolving incidents quickly. There are no significant limiting factors present in the provided data.",
        "flags": [],
        "gaps": [],
        "MetricID": "itsm.case_resolution_time",
        "Score": 5
      },
      "itsm.incident_reopen_rate": {
        "metric_id": "itsm.incident_reopen_rate",
        "band": 4,
        "rationale": "Reopen rate of 5% indicates a good first-time fix rate, but it is above the threshold for band 5. The limiting factor is the need to reduce the reopen rate further to achieve excellence.",
        "flags": [],
        "gaps": [
          "Reopen rate too high → analyze root causes of reopens and implement targeted training → achieve ≤2% reopen rate (unlocks band 5)."
        ],
        "MetricID": "itsm.incident_reopen_rate",
        "Score": 4
      },
      "hr.onboarding_cycle_time": {
        "metric_id": "hr.onboarding_cycle_time",
        "band": 4,
        "rationale": "Median 20h is strong, but the p90 of 36h indicates some variability in the process; approval delays could be a concern.",
        "flags": [
          "fast_bp"
        ],
        "gaps": [
          "Approval delays untracked → analyze approval step durations → reduce p90 approval time to ≤48h (unlocks band 5)."
        ],
        "MetricID": "hr.onboarding_cycle_time",
        "Score": 4
      },
      "sap.procure_to_pay_cycle": {
        "metric_id": "sap.procure_to_pay_cycle",
        "band": 2,
        "rationale": "Total days of 18 indicates a poor performance; while the breakdown shows some efficiency in individual stages, the overall duration exceeds the acceptable range significantly. The limiting factor is the total duration from PO creation to invoice posting.",
        "flags": [],
        "gaps": [
          "Total duration excessive → streamline processes in each stage → target ≤12d (unlocks band 3)."
        ],
        "MetricID": "sap.procure_to_pay_cycle",
        "Score": 2
      },
      "q2c.throughput": {
        "metric_id": "q2c.throughput",
        "band": 4,
        "rationale": "The total hours to cash is 16, which is within the good range; however, the reliance on specific order processing rates could limit scalability. ",
        "flags": [
          "good_time_to_cash"
        ],
        "gaps": [
          "Processing rate variability → analyze orders per hour by product type → achieve ≥2 orders/hour consistently (unlocks band 5)."
        ],
        "MetricID": "q2c.throughput",
        "Score": 4
      },
      "backlog.aging": {
        "metric_id": "backlog.aging",
        "band": 5,
        "rationale": "The median age of open items is excellent at 0.8 days, and the 90th percentile is also within the good range at 2.5 days; however, potential hidden issues may exist in specific queues.",
        "flags": [
          "low_queue_age"
        ],
        "gaps": [
          "Hidden pockets possible → publish per-queue age p95 and oldest 10 items → keep all queues p90 ≤3d (maintains band 5)."
        ],
        "MetricID": "backlog.aging",
        "Score": 5
      },
      "rpa.success_rate": {
        "metric_id": "rpa.success_rate",
        "band": 4,
        "rationale": "Overall success rate is 93%, with SFDC performing well at 95%, but SAP is lower at 91%, which limits the overall reliability perception. The strong performance of SFDC is a positive aspect.",
        "flags": [
          "good_reliability"
        ],
        "gaps": [
          "SAP performance lower → analyze and improve SAP RPA runs → achieve ≥95% success rate on SAP (unlocks band 5)."
        ],
        "MetricID": "rpa.success_rate",
        "Score": 4
      },
      "integration.data_sync_latency": {
        "metric_id": "integration.data_sync_latency",
        "band": 5,
        "rationale": "Median 12s and p95 18s indicate excellent performance; the failure rate is 0.0%, which is optimal.",
        "flags": [
          "near_real_time"
        ],
        "gaps": [],
        "MetricID": "integration.data_sync_latency",
        "Score": 5
      },
      "api.reliability": {
        "metric_id": "api.reliability",
        "band": 5,
        "rationale": "The p95 latency of 280 ms is within the SLO, and the error rate of 0.001% is excellent; however, endpoint-specific performance is not detailed.",
        "flags": [
          "headroom_present"
        ],
        "gaps": [
          "Endpoint performance details missing → report p95/error rates for top endpoints → ensure all meet SLO (solidifies band 5)."
        ],
        "MetricID": "api.reliability",
        "Score": 5
      },
      "integration.topology_health": {
        "metric_id": "integration.topology_health",
        "band": 2,
        "rationale": "Only 70% of nodes are healthy, indicating significant instability; the presence of 5 critical alerts further exacerbates the situation.",
        "flags": [],
        "gaps": [
          "low healthy node percentage → improve node stability and reduce critical errors → achieve ≥90% healthy nodes and ≤2 critical errors (unlocks band 3)."
        ],
        "MetricID": "integration.topology_health",
        "Score": 2
      },
      "mdm.duplicate_rate": {
        "metric_id": "mdm.duplicate_rate",
        "band": 4,
        "rationale": "A 3% duplicate rate indicates good matching and standardization; however, the lack of information on the trend limits confidence in sustained performance.",
        "flags": [
          "low_dupes"
        ],
        "gaps": [
          "Trend data missing → implement monthly tracking of duplicate rates over time → maintain ≤2% duplicates consistently (unlocks band 5)."
        ],
        "MetricID": "mdm.duplicate_rate",
        "Score": 4
      },
      "dq.exceptions_rate": {
        "metric_id": "dq.exceptions_rate",
        "band": 2,
        "rationale": "The exception rate of 6% indicates a significant issue with data quality, despite a lower critical rate of 2%. The high overall rate suggests that improvements are necessary to reduce the number of exceptions.",
        "flags": [],
        "gaps": [
          "High exception rate → implement targeted data quality initiatives → reduce overall exception rate to ≤3% (unlocks band 3)."
        ],
        "MetricID": "dq.exceptions_rate",
        "Score": 2
      },
      "ai.penetration": {
        "metric_id": "ai.penetration",
        "band": 3,
        "rationale": "AI features are present in 55% of workflows, but only 38% of executions utilize them; the execution share is a limiting factor. This indicates a fair level of integration but suggests that not all workflows are effectively leveraging AI in practice.",
        "flags": [],
        "gaps": [
          "Execution share low → increase training and support for AI features → target ≥50% execution share (unlocks band 4)."
        ],
        "MetricID": "ai.penetration",
        "Score": 3
      },
      "ai.outcome_uplift": {
        "metric_id": "ai.outcome_uplift",
        "band": 4,
        "rationale": "An estimated 11% uplift indicates a good improvement; however, the flat trend over the last 8 weeks suggests a lack of sustained growth. This limits the overall confidence in the improvement's stability.",
        "flags": [],
        "gaps": [
          "Stability unproven → include last 8–12 weeks trend for median and p90 → demonstrate non-declining trend (solidifies band 5)."
        ],
        "MetricID": "ai.outcome_uplift",
        "Score": 4
      },
      "ai.governance_coverage": {
        "metric_id": "ai.governance_coverage",
        "band": 4,
        "rationale": "Coverage is strong at 82%, indicating good governance controls; however, the absence of alerts raises concerns about ongoing monitoring effectiveness. The lack of alerts suggests potential gaps in active governance oversight.",
        "flags": [],
        "gaps": [
          "Monitoring effectiveness unclear → implement regular alert reviews and incident tracking → achieve consistent alerting on governance issues (unlocks band 5)."
        ],
        "MetricID": "ai.governance_coverage",
        "Score": 4
      },
      "platform.customization_debt": {
        "metric_id": "platform.customization_debt",
        "band": 3,
        "rationale": "The customization index is relatively low, indicating a moderate level of customization risk; however, the presence of unmanaged customizations and deprecated API calls suggests potential instability. The strongest positive is the low index, while the limiting factor is the unmanaged customizations and deprecated API calls.",
        "flags": [],
        "gaps": [
          "Unmanaged customizations and deprecated API calls present → implement a review process to address these issues → achieve 0 unmanaged customizations and deprecated API calls (unlocks band 4)."
        ],
        "MetricID": "platform.customization_debt",
        "Score": 3
      },
      "change.failure_rate": {
        "metric_id": "change.failure_rate",
        "band": 2,
        "rationale": "A change failure rate of 14% indicates significant reliability issues; while the number of deploys is reasonable, the high failure rate is a critical concern. The strong positive is the total number of deploys, but the failure rate is too high to achieve a better band.",
        "flags": [
          "high_cfr"
        ],
        "gaps": [
          "High failure rate → implement more rigorous testing and validation processes → reduce CFR to ≤7% (unlocks band 4)."
        ],
        "MetricID": "change.failure_rate",
        "Score": 2
      }
    },
    "mode": "single_inputs_json"
  }
]
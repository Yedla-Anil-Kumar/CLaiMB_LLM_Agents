[
  {
    "agent": "enterprise_systems",
    "metric_breakdown": {
      "process.automation.coverage": {
        "metric_id": "process.automation.coverage",
        "band": 4,
        "rationale": "The coverage ratio of 0.72 indicates good automation across multiple platforms, but it falls short of the excellent threshold. The strongest positive is the solid coverage, while the limiting factor is the need for broader execution across more platforms.",
        "flags": [],
        "gaps": [
          "Coverage uneven by platform → report coverage per platform and runs/week → achieve ≥0.85 coverage on ≥3 platforms (unlocks band 5)."
        ],
        "MetricID": "process.automation.coverage",
        "Score": 4
      },
      "workflow.sla_adherence": {
        "metric_id": "workflow.sla_adherence",
        "band": 4,
        "rationale": "On-time rate of 0.91 indicates good adherence to SLAs, with strong performance across systems; however, it is just below the threshold for an excellent rating.",
        "flags": [],
        "gaps": [
          "On-time rate near threshold → improve processes to increase on_time rate to ≥0.95 → unlocks band 5."
        ],
        "MetricID": "workflow.sla_adherence",
        "Score": 4
      },
      "sales.lead_to_oppty_cycle_time": {
        "metric_id": "sales.lead_to_oppty_cycle_time",
        "band": 3,
        "rationale": "The median of 28 hours indicates a fair performance, but it is above the threshold for band 3, and the lack of p90 data limits the assessment of tail risk. The strongest positive is the median being below 48 hours, while the absence of p90 data raises concerns about potential outliers.",
        "flags": [],
        "gaps": [
          "Tail risk unknown → add p90 latency for lead to opportunity conversion → keep p90 ≤48h (unlocks band 4)."
        ],
        "MetricID": "sales.lead_to_oppty_cycle_time",
        "Score": 3
      },
      "itsm.case_resolution_time": {
        "metric_id": "itsm.case_resolution_time",
        "band": 5,
        "rationale": "The median resolution time of 15 minutes indicates excellent performance, and the absence of limiting factors supports this high rating.",
        "flags": [],
        "gaps": [],
        "MetricID": "itsm.case_resolution_time",
        "Score": 5
      },
      "itsm.incident_reopen_rate": {
        "metric_id": "itsm.incident_reopen_rate",
        "band": 5,
        "rationale": "The reopen rate of 5% indicates a strong performance in resolving incidents on the first attempt. However, the lack of detail on priority mix may limit understanding of specific areas for improvement.",
        "flags": [],
        "gaps": [
          "Priority mix effects unknown → report reopen rates by priority code → achieve ≤2% for all priority levels (unlocks band 5)."
        ],
        "MetricID": "itsm.incident_reopen_rate",
        "Score": 5
      },
      "hr.onboarding_cycle_time": {
        "metric_id": "hr.onboarding_cycle_time",
        "band": 1,
        "rationale": "The median hours of 7 indicates a critical delay in the onboarding process; however, the lack of additional context on approval steps limits the assessment. The strong positive is the low median hours, but the critical band is due to the absence of data on approval tail risks.",
        "flags": [],
        "gaps": [
          "Approval delays untracked → implement tracking for approval times and identify bottlenecks → reduce median approval time to ≤24h (unlocks band 5)."
        ],
        "MetricID": "hr.onboarding_cycle_time",
        "Score": 1
      },
      "sap.procure_to_pay_cycle": {
        "metric_id": "sap.procure_to_pay_cycle",
        "band": 1,
        "rationale": "The total days of 18 exceeds the critical threshold of 20 days, indicating significant delays in the process; the lack of detailed breakdowns for sub-stages limits understanding of specific bottlenecks.",
        "flags": [],
        "gaps": [
          "High total days → analyze each stage for delays → reduce total days to ≤20 (unlocks band 2)."
        ],
        "MetricID": "sap.procure_to_pay_cycle",
        "Score": 1
      },
      "q2c.throughput": {
        "metric_id": "q2c.throughput",
        "band": 1,
        "rationale": "The total hours exceed the critical threshold, indicating severe delays in the process; the strong point is the initial quote to sales order timing, but the overall time to cash is unacceptable.",
        "flags": [],
        "gaps": [
          "Process bottlenecks identified → streamline approval workflows → reduce total hours to ≤12h (unlocks band 5)."
        ],
        "MetricID": "q2c.throughput",
        "Score": 1
      },
      "backlog.aging": {
        "metric_id": "backlog.aging",
        "band": 5,
        "rationale": "The median age of open items is very low (p50 0.8d, p90 2.5d), indicating efficient processing; however, potential hotspots in specific queues are not identified.",
        "flags": [
          "low_queue_age"
        ],
        "gaps": [
          "Hidden pockets possible → publish per-queue age p95 and oldest 10 items → keep all queues p90 ≤3d (maintains band 5)."
        ],
        "MetricID": "backlog.aging",
        "Score": 5
      },
      "rpa.success_rate": {
        "metric_id": "rpa.success_rate",
        "band": 4,
        "rationale": "The overall success rate is 93%, which is good, but it is on the lower end of the band. There is no information on retries or system-specific performance, which could provide more insight into reliability.",
        "flags": [],
        "gaps": [
          "Lack of system-specific data → report success rates per system and include retry metrics → achieve ≥95% success across all systems (unlocks band 5)."
        ],
        "MetricID": "rpa.success_rate",
        "Score": 4
      },
      "integration.data_sync_latency": {
        "metric_id": "integration.data_sync_latency",
        "band": 5,
        "rationale": "The median of 12 seconds and p95 of 12 seconds indicate excellent performance with no failures reported, showcasing a highly efficient delivery system.",
        "flags": [
          "excellent_performance"
        ],
        "gaps": [],
        "MetricID": "integration.data_sync_latency",
        "Score": 5
      },
      "api.reliability": {
        "metric_id": "api.reliability",
        "band": 5,
        "rationale": "The error rate of 0.1% is well below the SLO threshold, indicating excellent reliability; however, the p95 latency is not provided, which limits the assessment of latency performance.",
        "flags": [],
        "gaps": [
          "p95 latency unknown → provide p95 latency data for all endpoints → ensure p95 meets SLO (solidifies band 5)."
        ],
        "MetricID": "api.reliability",
        "Score": 5
      },
      "integration.topology_health": {
        "metric_id": "integration.topology_health",
        "band": 1,
        "rationale": "The average uptime is significantly low at 0.7%, indicating systemic failures across the integration nodes; the absence of healthy nodes further exacerbates the situation.",
        "flags": [],
        "gaps": [
          "systemic failures → implement robust monitoring and recovery strategies → achieve ≥99.5% uptime across all nodes (unlocks band 3)."
        ],
        "MetricID": "integration.topology_health",
        "Score": 1
      },
      "mdm.duplicate_rate": {
        "metric_id": "mdm.duplicate_rate",
        "band": 4,
        "rationale": "A 3% duplicate rate indicates good matching and standardization; however, the absence of trend data limits confidence in consistency.",
        "flags": [
          "good_dupes"
        ],
        "gaps": [
          "Trend data missing → implement monthly tracking of duplicate rates over time → maintain ≤2% duplicates consistently (unlocks band 5)."
        ],
        "MetricID": "mdm.duplicate_rate",
        "Score": 4
      },
      "dq.exceptions_rate": {
        "metric_id": "dq.exceptions_rate",
        "band": 2,
        "rationale": "The exception rate of 6% indicates a significant issue with data quality, despite the absence of detailed severity information. The high rate suggests that improvements are necessary to reduce the number of exceptions.",
        "flags": [],
        "gaps": [
          "High exception rate → implement targeted data quality initiatives → reduce rate to ≤3% (unlocks band 3)."
        ],
        "MetricID": "dq.exceptions_rate",
        "Score": 2
      },
      "ai.penetration": {
        "metric_id": "ai.penetration",
        "band": 3,
        "rationale": "AI is present in 55% of workflows, but the execution share is not provided, limiting the assessment. The positive aspect is the decent coverage of workflows, while the lack of execution data prevents a higher band rating.",
        "flags": [],
        "gaps": [
          "Execution share data missing → implement tracking for AI execution share → achieve ≥50% executions invoking AI (unlocks band 4)."
        ],
        "MetricID": "ai.penetration",
        "Score": 3
      },
      "ai.outcome_uplift": {
        "metric_id": "ai.outcome_uplift",
        "band": 4,
        "rationale": "An estimated uplift of 11% indicates a good improvement; however, the stability of this uplift over time is not confirmed.",
        "flags": [
          "good_uplift"
        ],
        "gaps": [
          "Stability unproven → include last 8–12 weeks trend for median and p90 → demonstrate non-declining trend (solidifies band 5)."
        ],
        "MetricID": "ai.outcome_uplift",
        "Score": 4
      },
      "ai.governance_coverage": {
        "metric_id": "ai.governance_coverage",
        "band": 4,
        "rationale": "Governance coverage is at 82%, which is strong, but there is no information on alerts or potential issues that could affect compliance. The lack of alert context limits the overall assessment of governance effectiveness.",
        "flags": [],
        "gaps": [
          "Alert context missing → implement a monitoring system for governance alerts → achieve ≤5 alerts/month (unlocks band 5)."
        ],
        "MetricID": "ai.governance_coverage",
        "Score": 4
      },
      "platform.customization_debt": {
        "metric_id": "platform.customization_debt",
        "band": 4,
        "rationale": "The customization index indicates a moderate-low risk with a relatively low footprint; however, the lack of detailed information on specific customizations limits the assessment of stability.",
        "flags": [
          "moderate_low_footprint"
        ],
        "gaps": [
          "Specific customization risks unknown → add detailed counts of unmanaged customizations and their impact → keep unmanaged customizations at 0 (unlocks band 5)."
        ],
        "MetricID": "platform.customization_debt",
        "Score": 4
      },
      "change.failure_rate": {
        "metric_id": "change.failure_rate",
        "band": 2,
        "rationale": "A 14% change failure rate indicates significant reliability issues; while the deployment count is not specified, the high failure rate is a critical concern. The lack of detailed deployment data limits the ability to assess the overall impact and trends.",
        "flags": [],
        "gaps": [
          "High failure rate → implement more rigorous testing and validation processes pre-deploy → reduce failure rate to ≤12% (unlocks band 3)."
        ],
        "MetricID": "change.failure_rate",
        "Score": 2
      }
    },
    "mode": "single_inputs_json"
  },
  {
    "agent": "enterprise_systems",
    "metric_breakdown": {
      "process.automation.coverage": {
        "metric_id": "process.automation.coverage",
        "band": 3,
        "rationale": "The coverage ratio of 0.61 indicates a fair level of automation, but it is siloed and lacks consistency across platforms. The strongest positive is the presence of some automated objects, while the limiting factor is the uneven distribution of automation across the systems.",
        "flags": [],
        "gaps": [
          "Coverage uneven by platform → report coverage per platform and runs/week → achieve ≥0.70 coverage on ≥2 platforms (unlocks band 4)."
        ],
        "MetricID": "process.automation.coverage",
        "Score": 3
      },
      "workflow.sla_adherence": {
        "metric_id": "workflow.sla_adherence",
        "band": 2,
        "rationale": "The on-time rate of 0.77 indicates a significant gap in meeting SLAs, with the performance falling into the poor category. While there is a measurable completion rate, it is insufficient to meet the minimum threshold for acceptable performance.",
        "flags": [],
        "gaps": [
          "On-time rate low → implement process improvements and training → achieve on-time rate ≥0.80 (unlocks band 3)."
        ],
        "MetricID": "workflow.sla_adherence",
        "Score": 2
      },
      "sales.lead_to_oppty_cycle_time": {
        "metric_id": "sales.lead_to_oppty_cycle_time",
        "band": 4,
        "rationale": "Median of 19h is good, and while the p90 is not excessively high, it indicates some variability in conversion times. The limiting factor is the median being above the 12-24h range, which prevents a higher band rating.",
        "flags": [],
        "gaps": [
          "Tail risk unknown → add p90 latency and failure % for conversion → keep p90 within 24h (unlocks band 5)."
        ],
        "MetricID": "sales.lead_to_oppty_cycle_time",
        "Score": 4
      },
      "itsm.case_resolution_time": {
        "metric_id": "itsm.case_resolution_time",
        "band": 5,
        "rationale": "The median resolution time of 25 minutes indicates excellent performance, and the absence of limiting factors suggests a strong operational capability. However, without additional context on incident priority, there is a slight uncertainty regarding the overall impact on critical incidents.",
        "flags": [],
        "gaps": [
          "Priority mix unclear → break out p90 by incident priority → ensure P1 p90 ≤90m (solidifies band 5)."
        ],
        "MetricID": "itsm.case_resolution_time",
        "Score": 5
      },
      "itsm.incident_reopen_rate": {
        "metric_id": "itsm.incident_reopen_rate",
        "band": 3,
        "rationale": "The reopen rate of 12% indicates a fair level of first-time resolution, but it is above the threshold for a higher band. The strongest positive is the acknowledgment of the issue, while the limiting factor is the high percentage of reopened incidents.",
        "flags": [],
        "gaps": [
          "High reopen rate → analyze root causes of reopened incidents → reduce reopen rate to ≤8% (unlocks band 4)."
        ],
        "MetricID": "itsm.incident_reopen_rate",
        "Score": 3
      },
      "hr.onboarding_cycle_time": {
        "metric_id": "hr.onboarding_cycle_time",
        "band": 5,
        "rationale": "The median onboarding time of 12 hours is excellent, indicating a highly efficient process; however, the approval tail is not detailed, which could introduce delays. ",
        "flags": [
          "fast_bp"
        ],
        "gaps": [
          "Approval delays untracked → analyze approval times for each step → ensure all steps are ≤24h (solidifies band 5)."
        ],
        "MetricID": "hr.onboarding_cycle_time",
        "Score": 5
      },
      "sap.procure_to_pay_cycle": {
        "metric_id": "sap.procure_to_pay_cycle",
        "band": 1,
        "rationale": "The total days of 21 exceeds the critical threshold; while there may be some efficiency in sub-stages, the overall process is severely delayed.",
        "flags": [],
        "gaps": [
          "Total days excessive → streamline approval and GR processes → target ≤20d (unlocks band 2)."
        ],
        "MetricID": "sap.procure_to_pay_cycle",
        "Score": 1
      },
      "q2c.throughput": {
        "metric_id": "q2c.throughput",
        "band": 5,
        "rationale": "The total of 10 hours from quote approval to billing is excellent; however, reliance on specific approver windows may affect consistency.",
        "flags": [
          "fast_time_to_cash"
        ],
        "gaps": [
          "Variability unknown → analyze throughput by product family/region → maintain p90 ≤18h across segments (solidifies band 5)."
        ],
        "MetricID": "q2c.throughput",
        "Score": 5
      },
      "backlog.aging": {
        "metric_id": "backlog.aging",
        "band": 5,
        "rationale": "The median age of open items is very low (p50 0.8d, p90 2.5d), indicating efficient processing; however, potential hotspots in specific queues are not identified.",
        "flags": [
          "low_queue_age"
        ],
        "gaps": [
          "Hidden pockets possible → publish per-queue age p95 and oldest 10 items → keep all queues p90 ≤3d (maintains band 5)."
        ],
        "MetricID": "backlog.aging",
        "Score": 5
      },
      "rpa.success_rate": {
        "metric_id": "rpa.success_rate",
        "band": 3,
        "rationale": "The overall success rate is 81%, which is within the fair range, but does not meet the threshold for a higher band. The positive aspect is that there is a measurable success rate, but the failure rate is significant enough to limit the evaluation.",
        "flags": [],
        "gaps": [
          "Success rate low → analyze failure causes and implement corrective actions → achieve ≥85% success rate (unlocks band 4)."
        ],
        "MetricID": "rpa.success_rate",
        "Score": 3
      },
      "integration.data_sync_latency": {
        "metric_id": "integration.data_sync_latency",
        "band": 4,
        "rationale": "The median of 35s and p95 of 35s indicate good performance, but the lack of failure percentage limits the assessment.",
        "flags": [
          "good_performance"
        ],
        "gaps": [
          "Failure context missing → provide failure % and retry metrics → keep failures <0.5% (unlocks band 5)."
        ],
        "MetricID": "integration.data_sync_latency",
        "Score": 4
      },
      "api.reliability": {
        "metric_id": "api.reliability",
        "band": 5,
        "rationale": "The error rate of 0.973% is slightly above the 0.5% threshold, but the p95 latency is not provided, making it difficult to assess fully; however, the error rate is still within a reasonable range for good performance.",
        "flags": [],
        "gaps": [
          "p95 latency unknown → provide p95 latency data → ensure it meets SLO (unlocks band 5)."
        ],
        "MetricID": "api.reliability",
        "Score": 5
      },
      "integration.topology_health": {
        "metric_id": "integration.topology_health",
        "band": 1,
        "rationale": "The average uptime is significantly low at 0.58%, indicating systemic failures across the integration nodes. The absence of healthy nodes and the presence of critical errors further exacerbate the situation.",
        "flags": [],
        "gaps": [
          "systemic failures → implement monitoring and remediation strategies → achieve ≥99.5% uptime across all nodes (unlocks band 3)."
        ],
        "MetricID": "integration.topology_health",
        "Score": 1
      },
      "mdm.duplicate_rate": {
        "metric_id": "mdm.duplicate_rate",
        "band": 3,
        "rationale": "A 9% duplicate rate indicates a fair level of matching, but it is above the threshold for a higher band; the number of duplicates is a limiting factor.",
        "flags": [],
        "gaps": [
          "High duplicate rate → implement stricter matching criteria and data cleansing processes → achieve ≤5% duplicates (unlocks band 4)."
        ],
        "MetricID": "mdm.duplicate_rate",
        "Score": 3
      },
      "dq.exceptions_rate": {
        "metric_id": "dq.exceptions_rate",
        "band": 1,
        "rationale": ">10% exception rate indicates critical data quality issues; the high rate is the strongest limiting factor.",
        "flags": [],
        "gaps": [
          "High exception rate → implement targeted data quality checks and remediation processes → reduce rate to ≤10% (unlocks band 2)."
        ],
        "MetricID": "dq.exceptions_rate",
        "Score": 1
      },
      "ai.penetration": {
        "metric_id": "ai.penetration",
        "band": 3,
        "rationale": "AI features are present in 33% of workflows, but the execution share is not provided, limiting the overall assessment. The positive aspect is the presence of AI in a third of workflows, but the lack of execution data prevents a higher band.",
        "flags": [],
        "gaps": [
          "Execution share unknown → measure execution share of AI features → achieve ≥50% execution share (unlocks band 4)."
        ],
        "MetricID": "ai.penetration",
        "Score": 3
      },
      "ai.outcome_uplift": {
        "metric_id": "ai.outcome_uplift",
        "band": 3,
        "rationale": "The estimated uplift of 5% indicates a fair improvement; however, it does not meet the threshold for a higher band. The strongest positive is the measurable uplift, while the limiting factor is the insufficient percentage increase.",
        "flags": [],
        "gaps": [
          "Uplift insufficient → increase KPI improvement strategies and monitor closely → achieve ≥10% uplift (unlocks band 4)."
        ],
        "MetricID": "ai.outcome_uplift",
        "Score": 3
      },
      "ai.governance_coverage": {
        "metric_id": "ai.governance_coverage",
        "band": 3,
        "rationale": "Coverage is at 65%, which is fair, but does not meet the threshold for a higher band; the lack of alerts suggests some stability in governance. However, the coverage is below the 75% mark, limiting the overall assessment.",
        "flags": [],
        "gaps": [
          "Coverage insufficient → increase share of models with required controls → achieve ≥75% coverage (unlocks band 4)."
        ],
        "MetricID": "ai.governance_coverage",
        "Score": 3
      },
      "platform.customization_debt": {
        "metric_id": "platform.customization_debt",
        "band": 3,
        "rationale": "The customization risk index indicates a moderate level of customization, suggesting some stability; however, the lack of detailed metrics on specific customizations limits the assessment of overall risk. The index value of 0.61 reflects a need for improvement in managing customizations effectively.",
        "flags": [],
        "gaps": [
          "Customization management unclear → implement tracking for unmanaged customizations and their impact → reduce unmanaged customizations to 0 (unlocks band 4)."
        ],
        "MetricID": "platform.customization_debt",
        "Score": 3
      },
      "change.failure_rate": {
        "metric_id": "change.failure_rate",
        "band": 2,
        "rationale": "A change failure rate of 25% indicates significant reliability issues; while the total deploys are not specified, the high failure rate is a critical concern. The lack of detailed deploy data limits the ability to assess the overall deployment strategy effectively.",
        "flags": [],
        "gaps": [
          "High failure rate → implement a robust pre-deployment testing strategy → achieve a failure rate ≤7% (unlocks band 4)."
        ],
        "MetricID": "change.failure_rate",
        "Score": 2
      }
    },
    "mode": "single_inputs_json"
  },
  {
    "agent": "enterprise_systems",
    "metric_breakdown": {
      "process.automation.coverage": {
        "metric_id": "process.automation.coverage",
        "band": 2,
        "rationale": "The coverage ratio of 0.44 indicates sporadic automation across the platforms, which is a significant limitation. While there is some automation present, it is not sufficient to demonstrate consistent coverage.",
        "flags": [],
        "gaps": [
          "Coverage uneven across platforms → increase automation efforts and track coverage per platform → achieve ≥0.70 coverage across ≥2 platforms (unlocks band 4)."
        ],
        "MetricID": "process.automation.coverage",
        "Score": 2
      },
      "workflow.sla_adherence": {
        "metric_id": "workflow.sla_adherence",
        "band": 2,
        "rationale": "The on-time rate is below 0.70, indicating significant issues with meeting SLAs; while there is a measurable completion rate, it is insufficient to meet expectations.",
        "flags": [],
        "gaps": [
          "On-time rate low → implement process improvements and monitoring → achieve on-time rate ≥0.80 (unlocks band 3)."
        ],
        "MetricID": "workflow.sla_adherence",
        "Score": 2
      },
      "sales.lead_to_oppty_cycle_time": {
        "metric_id": "sales.lead_to_oppty_cycle_time",
        "band": 3,
        "rationale": "The median of 35 hours indicates a fair performance, but the limiting factor is that it exceeds the upper threshold for band 3. The p90 hours are not provided, which could further clarify the tail risk.",
        "flags": [],
        "gaps": [
          "Lack of p90 data → include p90 hours for lead to opportunity conversion → achieve p90 ≤48h (unlocks band 4)."
        ],
        "MetricID": "sales.lead_to_oppty_cycle_time",
        "Score": 3
      },
      "itsm.case_resolution_time": {
        "metric_id": "itsm.case_resolution_time",
        "band": 5,
        "rationale": "Median resolution time of 40 minutes is excellent, and the p90 of 70 minutes further supports this performance. However, the impact of high-priority incidents is not detailed.",
        "flags": [
          "low_tail_risk"
        ],
        "gaps": [
          "Priority mix unclear → break out p50/p90 by P1/P2/P3 → ensure P1 p90 ≤90m (solidifies band 5)."
        ],
        "MetricID": "itsm.case_resolution_time",
        "Score": 5
      },
      "itsm.incident_reopen_rate": {
        "metric_id": "itsm.incident_reopen_rate",
        "band": 2,
        "rationale": "Reopen rate of 15% indicates significant issues with first-time resolution; while the data shows some incidents are resolved, the high reopen rate is a critical concern.",
        "flags": [],
        "gaps": [
          "High reopen rate → analyze root causes of reopens and implement corrective actions → reduce reopen rate to ≤12% (unlocks band 3)."
        ],
        "MetricID": "itsm.incident_reopen_rate",
        "Score": 2
      },
      "hr.onboarding_cycle_time": {
        "metric_id": "hr.onboarding_cycle_time",
        "band": 5,
        "rationale": "Median 20h is excellent, indicating efficient onboarding; however, the impact of specific approval chains is not evaluated.",
        "flags": [
          "fast_bp"
        ],
        "gaps": [
          "Bottlenecks hidden → list top 3 longest approval steps with median/p90 → keep worst-step p90 ≤48h (solidifies band 5)."
        ],
        "MetricID": "hr.onboarding_cycle_time",
        "Score": 5
      },
      "sap.procure_to_pay_cycle": {
        "metric_id": "sap.procure_to_pay_cycle",
        "band": 1,
        "rationale": "The total days of 29 is critical; the long duration indicates significant inefficiencies in the process. The strongest positive is the identification of the issue, but the overall timing is far beyond acceptable limits.",
        "flags": [],
        "gaps": [
          "Excessive total days → analyze each stage for delays → reduce total days to ≤20d (unlocks band 2)."
        ],
        "MetricID": "sap.procure_to_pay_cycle",
        "Score": 1
      },
      "q2c.throughput": {
        "metric_id": "q2c.throughput",
        "band": 5,
        "rationale": "10 hours total is excellent, indicating a strong time-to-cash performance; however, reliance on specific approver windows could limit consistency in the process.",
        "flags": [
          "fast_time_to_cash"
        ],
        "gaps": [
          "Variability unknown → analyze approval times by department → ensure ≤12h across all departments (unlocks band 5)."
        ],
        "MetricID": "q2c.throughput",
        "Score": 5
      },
      "backlog.aging": {
        "metric_id": "backlog.aging",
        "band": 5,
        "rationale": "The median age of open items is excellent (p50 0.8d, p90 2.5d), indicating a quick turnaround. However, the potential for hidden issues in specific queues is a limiting factor.",
        "flags": [
          "low_queue_age"
        ],
        "gaps": [
          "Hidden pockets possible → publish per-queue age p95 and oldest 10 items → keep all queues p90 ≤3d (maintains band 5)."
        ],
        "MetricID": "backlog.aging",
        "Score": 5
      },
      "rpa.success_rate": {
        "metric_id": "rpa.success_rate",
        "band": 1,
        "rationale": "The overall success ratio is 63%, which is below the critical threshold of 70%. This indicates significant reliability issues in RPA runs, with no evidence of successful performance improvement strategies.",
        "flags": [],
        "gaps": [
          "Success rate low → implement monitoring and optimization strategies → achieve ≥70% success rate (unlocks band 2)."
        ],
        "MetricID": "rpa.success_rate",
        "Score": 1
      },
      "integration.data_sync_latency": {
        "metric_id": "integration.data_sync_latency",
        "band": 4,
        "rationale": "The median of 55s is within the acceptable range for band 4, and the p95 of 55s is also strong. However, without failure percentage data, the overall reliability of the delivery cannot be fully assessed.",
        "flags": [],
        "gaps": [
          "Failure context missing → provide failure % and retry metrics → keep failures <0.5% (unlocks band 5)."
        ],
        "MetricID": "integration.data_sync_latency",
        "Score": 4
      },
      "api.reliability": {
        "metric_id": "api.reliability",
        "band": 5,
        "rationale": "The error rate of 0.945% is slightly above the 0.5% threshold, but the p95 latency is within SLO, indicating strong performance overall; however, the error rate is a limiting factor.",
        "flags": [],
        "gaps": [
          "Error rate slightly above SLO → implement error tracking and resolution processes → reduce error rate to ≤0.5% (unlocks band 5)."
        ],
        "MetricID": "api.reliability",
        "Score": 5
      },
      "integration.topology_health": {
        "metric_id": "integration.topology_health",
        "band": 1,
        "rationale": "The average uptime is significantly low at 0.41%, indicating systemic failures across the integration nodes. The absence of healthy nodes and the presence of critical errors further exacerbate the situation.",
        "flags": [],
        "gaps": [
          "systemic failures → implement monitoring and remediation strategies → achieve ≥99.5% uptime across all nodes (unlocks band 3)."
        ],
        "MetricID": "integration.topology_health",
        "Score": 1
      },
      "mdm.duplicate_rate": {
        "metric_id": "mdm.duplicate_rate",
        "band": 2,
        "rationale": "A duplicate rate of 16% indicates significant issues with entity matching and standardization; while the total number of entities evaluated is not provided, the high duplication suggests systemic problems. The strongest positive is the identification of duplicates, but the high rate limits overall effectiveness.",
        "flags": [],
        "gaps": [
          "High duplicate rate → implement stricter matching criteria and data cleansing processes → achieve ≤10% duplicates (unlocks band 3)."
        ],
        "MetricID": "mdm.duplicate_rate",
        "Score": 2
      },
      "dq.exceptions_rate": {
        "metric_id": "dq.exceptions_rate",
        "band": 2,
        "rationale": "The exception rate of 19% indicates a critical level of issues, despite the absence of detailed severity data. The high rate suggests significant underlying problems that need addressing.",
        "flags": [],
        "gaps": [
          "High exception rate → implement targeted rule evaluations and remediation plans → reduce rate to ≤10% (unlocks band 3)."
        ],
        "MetricID": "dq.exceptions_rate",
        "Score": 2
      },
      "ai.penetration": {
        "metric_id": "ai.penetration",
        "band": 1,
        "rationale": "AI is present in less than 10% of workflows, indicating minimal adoption; the execution share is also low at 0.18. This critical limitation suggests a lack of integration of AI features in the overall system.",
        "flags": [],
        "gaps": [
          "Low AI workflow coverage → increase workflows with AI features to at least 10% → target ≥10% workflows with AI (unlocks band 2)."
        ],
        "MetricID": "ai.penetration",
        "Score": 1
      },
      "ai.outcome_uplift": {
        "metric_id": "ai.outcome_uplift",
        "band": 2,
        "rationale": "The estimated uplift of 2% indicates minimal improvement; the lack of significant change limits the overall effectiveness of the AI rollout.",
        "flags": [],
        "gaps": [
          "Minimal uplift → identify specific areas for improvement and implement targeted strategies → achieve ≥10% uplift (unlocks band 4)."
        ],
        "MetricID": "ai.outcome_uplift",
        "Score": 2
      },
      "ai.governance_coverage": {
        "metric_id": "ai.governance_coverage",
        "band": 2,
        "rationale": "Only 39% of models have the required governance controls, indicating significant gaps in compliance; the lack of sufficient coverage is the primary limiting factor.",
        "flags": [],
        "gaps": [
          "Low coverage → implement governance controls for all models → achieve ≥75% coverage (unlocks band 4)."
        ],
        "MetricID": "ai.governance_coverage",
        "Score": 2
      },
      "platform.customization_debt": {
        "metric_id": "platform.customization_debt",
        "band": 3,
        "rationale": "The customization risk index indicates a moderate level of customization, suggesting some stability; however, the lack of detailed metrics on specific customizations limits the assessment of overall risk.",
        "flags": [],
        "gaps": [
          "Customization details lacking → provide counts of unmanaged customizations and deprecated API usage → keep unmanaged/deprecated at 0 (unlocks band 4)."
        ],
        "MetricID": "platform.customization_debt",
        "Score": 3
      },
      "change.failure_rate": {
        "metric_id": "change.failure_rate",
        "band": 2,
        "rationale": "A change failure rate of 33% indicates significant reliability issues; while the high failure rate is a strong negative, there is no additional context provided to suggest improvement strategies.",
        "flags": [],
        "gaps": [
          "High failure rate → implement a robust change management process with clear rollback strategies → reduce failure rate to ≤20% (unlocks band 3)."
        ],
        "MetricID": "change.failure_rate",
        "Score": 2
      }
    },
    "mode": "single_inputs_json"
  },
  {
    "agent": "enterprise_systems",
    "metric_breakdown": {
      "process.automation.coverage": {
        "metric_id": "process.automation.coverage",
        "band": 4,
        "rationale": "The coverage ratio of 0.72 indicates good automation across multiple platforms, with ServiceNow showing the highest coverage. However, the coverage in Salesforce and SAP is slightly lower, limiting the overall score.",
        "flags": [
          "multi_platform_coverage"
        ],
        "gaps": [
          "Coverage uneven by platform → report coverage per platform and runs/week → achieve ≥0.85 coverage on ≥3 platforms (unlocks band 5)."
        ],
        "MetricID": "process.automation.coverage",
        "Score": 4
      },
      "workflow.sla_adherence": {
        "metric_id": "workflow.sla_adherence",
        "band": 4,
        "rationale": "The overall on-time rate of 0.91 is strong, particularly with high priority cases at 0.94; however, normal priority cases at 0.89 slightly limit the overall performance. ",
        "flags": [],
        "gaps": [
          "Coverage uneven by priority → report on-time rates for each priority level → achieve ≥0.90 on normal priority cases (unlocks band 5)."
        ],
        "MetricID": "workflow.sla_adherence",
        "Score": 4
      },
      "sales.lead_to_oppty_cycle_time": {
        "metric_id": "sales.lead_to_oppty_cycle_time",
        "band": 3,
        "rationale": "The median of 28 hours is fair, but the p90 at 52 hours indicates a significant tail risk. This discrepancy limits the overall performance despite a reasonable median time.",
        "flags": [],
        "gaps": [
          "Tail risk unknown → add p95 latency and failure % → keep p95 within 48h (unlocks band 4)."
        ],
        "MetricID": "sales.lead_to_oppty_cycle_time",
        "Score": 3
      },
      "itsm.case_resolution_time": {
        "metric_id": "itsm.case_resolution_time",
        "band": 5,
        "rationale": "The median resolution time of 15 minutes and p90 of 35 minutes indicate excellent performance in incident resolution. There are no significant limiting factors present.",
        "flags": [],
        "gaps": [],
        "MetricID": "itsm.case_resolution_time",
        "Score": 5
      },
      "itsm.incident_reopen_rate": {
        "metric_id": "itsm.incident_reopen_rate",
        "band": 4,
        "rationale": "Reopen rate of 5% indicates a good first-time fix rate, but it is above the threshold for band 5. The limiting factor is the need to further reduce the reopen rate to achieve excellence.",
        "flags": [],
        "gaps": [
          "Reopen rate high → analyze root causes of reopened incidents → reduce reopen rate to ≤2% (unlocks band 5)."
        ],
        "MetricID": "itsm.incident_reopen_rate",
        "Score": 4
      },
      "hr.onboarding_cycle_time": {
        "metric_id": "hr.onboarding_cycle_time",
        "band": 4,
        "rationale": "Median 7 days (168h) is above the threshold for band 4, but the p90 of 12 days (288h) indicates potential delays; the strong positive is the median being within the band 4 range, while the p90 suggests room for improvement in approval processes.",
        "flags": [],
        "gaps": [
          "High p90 hours → analyze top 3 longest approval steps with median/p90 → reduce worst-step p90 to ≤48h (unlocks band 5)."
        ],
        "MetricID": "hr.onboarding_cycle_time",
        "Score": 4
      },
      "sap.procure_to_pay_cycle": {
        "metric_id": "sap.procure_to_pay_cycle",
        "band": 2,
        "rationale": "Total days of 18 indicates a poor performance; while the breakdown shows some efficiency in individual stages, the overall duration exceeds the acceptable range significantly. The strongest positive is the relatively short requisition and PO stages, but the lengthy invoice processing time is a limiting factor.",
        "flags": [],
        "gaps": [
          "Invoice processing delays → streamline invoice approval process → target ≤5d (unlocks band 4)."
        ],
        "MetricID": "sap.procure_to_pay_cycle",
        "Score": 2
      },
      "q2c.throughput": {
        "metric_id": "q2c.throughput",
        "band": 4,
        "rationale": "The total hours to cash is 16, which is good; however, the reliance on specific order processing rates could limit scalability during peak times.",
        "flags": [
          "good_time_to_cash"
        ],
        "gaps": [
          "Processing rate variability → analyze throughput during peak hours → achieve consistent orders per hour ≥2 (unlocks band 5)."
        ],
        "MetricID": "q2c.throughput",
        "Score": 4
      },
      "backlog.aging": {
        "metric_id": "backlog.aging",
        "band": 5,
        "rationale": "The median age of open items is excellent at 0.8 days, and the 90th percentile is also within the good range at 2.5 days; however, potential hidden issues may exist in specific queues.",
        "flags": [
          "low_queue_age"
        ],
        "gaps": [
          "Hidden pockets possible → publish per-queue age p95 and oldest 10 items → keep all queues p90 ≤3d (maintains band 5)."
        ],
        "MetricID": "backlog.aging",
        "Score": 5
      },
      "rpa.success_rate": {
        "metric_id": "rpa.success_rate",
        "band": 4,
        "rationale": "Overall success rate is 93%, with SFDC performing well at 95%, but SAP is lower at 91%, which limits the overall reliability perception.",
        "flags": [
          "good_reliability"
        ],
        "gaps": [
          "SAP performance lower → analyze and improve SAP RPA runs → achieve ≥95% success rate on SAP (unlocks band 5)."
        ],
        "MetricID": "rpa.success_rate",
        "Score": 4
      },
      "integration.data_sync_latency": {
        "metric_id": "integration.data_sync_latency",
        "band": 5,
        "rationale": "Median 12s and p95 18s indicate excellent performance with no delivery failures, showcasing a highly efficient system.",
        "flags": [
          "near_real_time"
        ],
        "gaps": [
          "Failure context missing → provide failure %, retry storms, and DLQ rate → keep failures ≤0.2% and DLQ ≈0 (solidifies band 5)."
        ],
        "MetricID": "integration.data_sync_latency",
        "Score": 5
      },
      "api.reliability": {
        "metric_id": "api.reliability",
        "band": 5,
        "rationale": "The p95 latency of 280 ms is within the SLO, and the error rate of 0.001% is excellent; however, the SLO threshold for latency is not provided for comparison.",
        "flags": [],
        "gaps": [],
        "MetricID": "api.reliability",
        "Score": 5
      },
      "integration.topology_health": {
        "metric_id": "integration.topology_health",
        "band": 2,
        "rationale": "Only 70% of nodes are healthy, indicating significant instability; the presence of 5 critical errors further exacerbates the situation.",
        "flags": [],
        "gaps": [
          "low healthy node percentage → increase node health monitoring and remediation efforts → achieve ≥90% healthy nodes (unlocks band 3)."
        ],
        "MetricID": "integration.topology_health",
        "Score": 2
      },
      "mdm.duplicate_rate": {
        "metric_id": "mdm.duplicate_rate",
        "band": 4,
        "rationale": "A 3% duplicate rate indicates good matching and standardization; however, the lack of trend data limits confidence in sustained performance.",
        "flags": [
          "low_dupes"
        ],
        "gaps": [
          "Trend data missing → implement monthly tracking of duplicate rates over time → maintain ≤3% to solidify band 5."
        ],
        "MetricID": "mdm.duplicate_rate",
        "Score": 4
      },
      "dq.exceptions_rate": {
        "metric_id": "dq.exceptions_rate",
        "band": 2,
        "rationale": "The exception rate of 6% indicates a significant issue with data quality, despite a lower critical rate of 2%. The high overall rate suggests that improvements are necessary to reduce the number of exceptions.",
        "flags": [],
        "gaps": [
          "High exception rate → implement targeted data quality initiatives → reduce overall exception rate to ≤3% (unlocks band 4)."
        ],
        "MetricID": "dq.exceptions_rate",
        "Score": 2
      },
      "ai.penetration": {
        "metric_id": "ai.penetration",
        "band": 3,
        "rationale": "AI is present in 55% of workflows, but only 38% of executions utilize AI features; the execution share is a limiting factor. ",
        "flags": [],
        "gaps": [
          "Execution share low → increase AI execution share → target ≥50% (unlocks band 4)."
        ],
        "MetricID": "ai.penetration",
        "Score": 3
      },
      "ai.outcome_uplift": {
        "metric_id": "ai.outcome_uplift",
        "band": 4,
        "rationale": "An estimated uplift of 11% indicates a good improvement; however, the flat trend over the last 8 weeks raises concerns about sustainability. The strong positive is the uplift percentage, while the limiting factor is the lack of a positive trend.",
        "flags": [
          "good_uplift"
        ],
        "gaps": [
          "Stability unproven → include last 8–12 weeks trend for median and p90 → demonstrate non-declining trend (solidifies band 5)."
        ],
        "MetricID": "ai.outcome_uplift",
        "Score": 4
      },
      "ai.governance_coverage": {
        "metric_id": "ai.governance_coverage",
        "band": 4,
        "rationale": "Coverage is at 82%, which is strong, but the absence of alerts in the last 30 days does not provide insight into ongoing governance effectiveness. The lack of alerts is a positive signal, but it does not compensate for the need for continuous monitoring and validation of controls.",
        "flags": [],
        "gaps": [
          "Continuous monitoring lacking → implement regular governance audits and alerts → achieve ≥90% coverage with active monitoring (unlocks band 5)."
        ],
        "MetricID": "ai.governance_coverage",
        "Score": 4
      },
      "platform.customization_debt": {
        "metric_id": "platform.customization_debt",
        "band": 3,
        "rationale": "Moderate customization footprint with some unmanaged customizations and deprecated API calls; while the index is low, the presence of these factors indicates potential risk. The strongest positive is the low index, but the unmanaged customizations and deprecated calls limit stability.",
        "flags": [],
        "gaps": [
          "Unmanaged customizations present → reduce unmanaged customizations to 0 → achieve a stable customization environment (unlocks band 4)."
        ],
        "MetricID": "platform.customization_debt",
        "Score": 3
      },
      "change.failure_rate": {
        "metric_id": "change.failure_rate",
        "band": 2,
        "rationale": "A change failure rate of 14% indicates significant reliability issues; while the number of deploys is substantial, the high failure rate is a critical concern. The strong positive is the volume of deploys, but the limiting factor is the high proportion of failures and rollbacks.",
        "flags": [
          "high_cfr"
        ],
        "gaps": [
          "High failure rate → implement stricter pre-deployment testing and validation processes → reduce CFR to ≤7% (unlocks band 4)."
        ],
        "MetricID": "change.failure_rate",
        "Score": 2
      }
    },
    "mode": "single_inputs_json"
  }
]